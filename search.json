[{"title":"Ceph MDS Stuck in Client Replay 问题分析","path":"/posts/2094044811/","content":"最近一直在做 MDS 高可用方面的工作，发现 MDS （带 IO）重启时可能会长时间卡在 Client Replay 状态。这里对问题的原因做了一下分析，并给出了现有的以及未来的解决办法，希望能对大家有所帮助。 问题现象梳理通过 ceph -s 看到 MDS 的状态长时间在 client replay 状态不变化： 1234[root@node2 ~]# ceph -s cluster: ... mds: cephfs: 1/1 &#123;0=node2=up:clientreplay&#125; 查看 MDS 状态会发现 clientreplay_queue 不为空，但是如果打开 MDS 日志会发现 MDS 什么都没做（除了心跳）： 12345678ceph tell mds.ocs-storagecluster-cephfilesystem:0 status&#123; ... &quot;clientreplay_status&quot;: &#123; &quot;clientreplay_queue&quot;: 125048, &quot;active_replay&quot;: 0 &#125;,&#125; 原因分析那这里我们要分析这个问题，就要先知道 MDS 在 Client Replay 阶段做了什么。 首先我们知道 MDS 在启动过程中在 Replay 阶段完成以后（多 MDS 要在 Resolve 阶段以后）会进入 Reconnect 阶段，这个阶段顾名思义会等待客户端进行重连，这也是 MDS 在进入 Active 状态之前唯一能接收客户端请求的阶段，因此客户端会在这个阶段通过 Client::send_reconnect 向 MDS 发送 unsafe_requests, old_requests 以及 client_reconnect 消息, 其中 unsafe_requests 会通过 enqueue_replay 加入 replay_queue 中，old_requests 则会加入 waiting_for_active 等待 MDS 到 active 再处理，client_reconnect 消息则是客户端向 MDS 发送的最后一条消息表示客户端重连完成了（如果 MDS 没有收到这条消息就会把客户端 kill 掉） 12345678void Server::dispatch(const cref_t&lt;Message&gt; &amp;m)&#123; ... if (queue_replay) &#123; req-&gt;mark_queued_for_replay(); mds-&gt;enqueue_replay(new C_MDS_RetryMessage(mds, m)); return; &#125; 接着 MDS 到达 Client Replay 阶段之后就会从 replay_queue 中依次取出刚刚插入的消息并处理，如果一切正常的话每条消息都会在处理完成后 Server::journal_and_reply 或者 Server::reply_client_request 中通过 queue_one_replay 取出下一条消息并处理。 但问题在于并不是每一种情况 MDS 都能 cover 到，首先在任何情况下 Client 都有可能掉线，这导致 MDS 可能在任何时刻 kill_session （一个比较常见的情况是 ganesha 在 client_metadata 里设置了 timeout 所以没有在 Reconnect 阶段 kill_session） 那么如果处理消息时 client session 被 kill 掉又会发生什么呢，正常情况下在 Server::handle_client_request 中如果发现这个 session 被 kill 了那么会 queue_one_replay 处理下一个消息： 1234567void Server::handle_client_request(const cref_t&lt;MClientRequest&gt; &amp;req)&#123; if (!session) &#123; if (req-&gt;is_queued_for_replay()) mds-&gt;queue_one_replay(); return; &#125; 但是如果这个消息此时不是刚开始处理的话就会遇到问题了，假设此前处理请求时候,需要拿锁 Server::acquire_locks： 12022-03-15 12:22:40.185171 7f3e57e90700 10 mds.0.locker wrlock_start (inest sync dirty) on ... 这里拿 wrlock 想要把 inest 锁从 sync 状态转成 lock 状态，但是因为此时 inest 锁状态是 dirty 的，因此需要通过 scatter_writebehind 刷一把 journal，并 WAIT_STABLE: 123456789bool Locker::wrlock_start(const MutationImpl::LockOp &amp;op, MDRequestRef&amp; mut)&#123; ... dout(7) &lt;&lt; &quot;wrlock_start waiting on &quot; &lt;&lt; *lock &lt;&lt; &quot; on &quot; &lt;&lt; *lock-&gt;get_parent() &lt;&lt; dendl; lock-&gt;add_waiter(SimpleLock::WAIT_STABLE, new C_MDS_RetryRequest(mdcache, mut)); nudge_log(lock); return false;&#125; 这里注意 add_waiter 设置的回调是 C_MDS_RetryRequest 和之前加入 replay_queue 时的 C_MDS_RetryMessage 是不一样的，这里就是问题的关键。 当 scatter_writebehind 完成之后由 scatter_writebehind_finish 调到 C_MDS_RetryRequest::finish 12345void C_MDS_RetryRequest::finish(int r)&#123; mdr-&gt;retry++; cache-&gt;dispatch_request(mdr);&#125; 这里直接进入了 MDCache::dispatch_request: 1234void MDCache::dispatch_request(MDRequestRef&amp; mdr)&#123; if (mdr-&gt;client_request) &#123; mds-&gt;server-&gt;dispatch_client_request(mdr); 可以看到这里没有走 Server::handle_client_request 而是直接进入了 Server::dispatch_client_request，在这里对于已经被 kill 掉的 session 的处理就有一个 corner case: 12345678910void Server::dispatch_client_request(MDRequestRef&amp; mdr)&#123; // we shouldn&#x27;t be waiting on anyone. ceph_assert(!mdr-&gt;has_more() || mdr-&gt;more()-&gt;waiting_on_peer.empty()); if (mdr-&gt;killed) &#123; dout(10) &lt;&lt; &quot;request &quot; &lt;&lt; *mdr &lt;&lt; &quot; was killed&quot; &lt;&lt; dendl; return; &#125; ... 这里可以看到直接 return 掉了而没有进行 queue_one_replay，这就使得 MDS 没有办法继续往下进行了 除了这种情况以外在 MDCache::request_start 失败时也会直接返回而不会有机会 queue_one_replay 如何解决目前遇到这种情况没有其他办法，只能通过重启 MDS 来解决（因为没有机会触发 queue_one_replay） 社区的相关进展这个问题实际上社区很早就发现了， queue_one_replay 这个改动就是 YanZheng 在 6352f181 为了 fix ‘stuck in clientreplay’ 的问题提的，但是实际上就像我上面分析的还有一些 corner case 没有覆盖到，这就导致在一些场景下我们仍会遇到这样的问题。 最新的话是 Patrick 在 #47121 中提了一个改动想统一一下 queue_one_replay 的位置，正好我前两天分析了这一块所以给 Patrick 说了现有的这些可能导致 MDS 卡住的情况，然后后面我会再看一下他提的这个 PR 能不能解决问题，如果可以的话后面合到主线应该就不会出现这种问题了。","tags":["Ceph"]},{"title":"如何实现一个最小堆","path":"/posts/2906464195/","content":"本文介绍如何使用 C++ 实现一个通用的、线程安全的最小堆 顺便一提，写此文的时候突然想到了多年以前（16、17年）盛行的 Mooc，当时国内有很多类似的慕课网站，也有很多优秀的课程，我的基础数据结构和算法就是一位 ACM 铜牌的老师教的，至今受用，但是现在好像很少看到此类网站了，还是比较可惜的。 进入正题，最小堆本身是一个完全二叉树，保证每一个节点都不会大于其左右子节点，要实现一个最小堆的两个核心函数是 sift_up 和 sift_down，用于调整最小堆结构以符合定义。 首先给出 MinHeap 的基本定义和成员变量： 123456template &lt;std::three_way_comparable T&gt;class MinHeap&#123; std::shared_mutex mtx; std::vector&lt;T&gt; vec;&#125;; 这里 vec 用于保存最小堆的各个节点（完全二叉树很适合用数组保存），而 std::three_way_comparable 则是对容器元素类型的 concept 约束，要求元素类型必须是可比较的，毕竟不可比较的话也就没有“最小”的概念了。 sift_down 和 sift_up 是相反的一组用于调整堆的操作，sift_down 用于将一个元素向下调整至满足最小堆的条件，sift_up 则相反，由此可以知道对于任何一个完全二叉数我们只需要上到下执行 sift_down 或者从下到上执行 sift_up 就可以使得堆中的每一个节点都满足最小堆的条件 123 5 sift_down(5) 2 / \\ ==============&gt; / \\ 2 6 sift_up(2) 5 6 可以看到不管是对 2 所在的节点执行 sift_up 还是对 5 所在的节点执行 sift_down 都能完成我们想要的效果。 接着在给出二者的定义前先给出对最小堆的一些基本操作： 123456789101112131415161718192021public:void push (T val)&#123; std::unique_lock lock &#123;mtx&#125;; vec.push_back(val); sift_up(vec.size()-1);&#125;void pop()&#123; assert(!vec.empty()); std::unique_lock lock &#123;mtx&#125;; vec[0] = vec.back(); vec.pop_back(); sift_down(0);&#125;const T&amp; top()&#123; assert(!vec.empty()); std::shared_lock lock &#123;mtx&#125;; return vec.front();&#125; push 和 pop 就是对堆调整以符合最小堆定义的过程，因为每次只有一个节点发生变化（新增或者删除），所以只需要对涉及的节点调整即可 下面给出 sift_up 和 sift_down 的定义如下： 12345678910111213141516171819202122232425262728void sift_up(size_t index)&#123; if (index == 0) return; size_t parent = (index - 1) / 2; if (vec[index] &lt; vec[parent]) &#123; std::swap(vec[index], vec[parent]); sift_up(parent); &#125;&#125;void sift_down(size_t index)&#123; if (index &gt;= vec.size()) return; size_t left = index * 2 + 1; size_t right = index * 2 + 2; std::optional&lt;size_t&gt; swap_to; if (left &lt; vec.size() &amp;&amp; vec[left] &lt; vec[index]) &#123; swap_to = left; &#125; if (right &lt; vec.size() &amp;&amp; vec[right] &lt; vec[index]) &#123; if (!swap_to || vec[right] &lt; vec[swap_to.value()]) &#123; swap_to = right; &#125; &#125; if (swap_to) &#123; std::swap(vec[index], vec[swap_to.value()]); sift_down(swap_to.value()); &#125;&#125; 应该还是比较好理解的，因为只有一个节点不（一定）满足最小堆条件，因此对于 sift_up 只需要判断自身和其父节点的大小关系并交换即可，而对于 sift_down 则是需要选出两个子节点中更小的那个并与之交换。 注意这里的 sift_up 和 sift_down 都是一个递归的过程，直到抵达堆的根节点或者叶子节点 以上我们就已经实现了一个通用的、线程安全的最小堆，这里给出堆的完整定义（为了方便使用包含 dump）： 完整的 MinHeap 实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667template &lt;std::three_way_comparable T&gt;class MinHeap&#123; std::shared_mutex mtx; std::vector&lt;T&gt; vec;public: void push (T val) &#123; std::unique_lock lock &#123;mtx&#125;; vec.push_back(val); sift_up(vec.size()-1); &#125; void pop() &#123; assert(!vec.empty()); std::unique_lock lock &#123;mtx&#125;; vec[0] = vec.back(); vec.pop_back(); sift_down(0); &#125; const T&amp; top() &#123; assert(!vec.empty()); std::shared_lock lock &#123;mtx&#125;; return vec.front(); &#125; void sift_up(size_t index) &#123; if (index == 0) return; size_t parent = (index - 1) / 2; if (vec[index] &lt; vec[parent]) &#123; std::swap(vec[index], vec[parent]); sift_up(parent); &#125; &#125; void sift_down(size_t index) &#123; if (index &gt;= vec.size()) return; size_t left = index * 2 + 1; size_t right = index * 2 + 2; std::optional&lt;size_t&gt; swap_to; if (left &lt; vec.size() &amp;&amp; vec[left] &lt; vec[index]) &#123; swap_to = left; &#125; if (right &lt; vec.size() &amp;&amp; vec[right] &lt; vec[index]) &#123; if (!swap_to || vec[right] &lt; vec[swap_to.value()]) &#123; swap_to = right; &#125; &#125; if (swap_to) &#123; std::swap(vec[index], vec[swap_to.value()]); sift_down(swap_to.value()); &#125; &#125; void dump() &#123; std::shared_lock lock &#123;mtx&#125;; for (auto iter = vec.begin(); iter != vec.end(); ++iter) &#123; std::cout &lt;&lt; *iter; if (std::distance(iter, vec.end()) != 1) &#123; std::cout &lt;&lt; &quot;, &quot;; &#125; else &#123; std::cout &lt;&lt; std::endl; &#125; &#125; &#125;&#125;; 用法示例以及运行结果如下： 123456789101112131415161718auto main(void) -&gt; int &#123; auto heap = MinHeap&lt;int&gt; &#123;&#125;; heap.push(177); heap.push(3); heap.push(110); heap.push(19); heap.pop(); heap.push(21); heap.push(112); heap.push(18); std::cout &lt;&lt; &quot;heap&#x27;s top is &quot; &lt;&lt; heap.top() &lt;&lt; std::endl; heap.dump(); heap.pop(); heap.pop(); std::cout &lt;&lt; &quot;heap&#x27;s top is &quot; &lt;&lt; heap.top() &lt;&lt; std::endl; heap.dump(); return 0;&#125; 运行结果： 1234heap&#x27;s top is 1818, 21, 19, 177, 112, 110heap&#x27;s top is 2121, 112, 110, 177 可以看到不论我们以任何顺序插入和删除元素都能够保证 MinHeap 始终是一个最小堆","tags":["C++"]},{"title":"C++ Coroutine: 通用异步任务 Task","path":"/posts/3692590940/","content":"本文使用协程实现了一个通用的异步任务执行类 Task，支持设置回调函数并将在 Task 完成后执行回调。 Task、TaskPromise 和 TaskAwaiter 覆盖到了大部分的协程执行过程，把这几个类的实现理解了那基本上就可以说已经理解了 c++ 协程的工作方式。 阅读下面这段代码的方式建议通过 main 函数开始，对照运行结果一点一点来看。 Source Code123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322#include &lt;iostream&gt;#include &lt;coroutine&gt;#include &lt;functional&gt;#include &lt;exception&gt;#include &lt;optional&gt;#include &lt;atomic&gt;#include &lt;utility&gt;#include &lt;chrono&gt;#include &lt;thread&gt;#include &lt;list&gt;#include &lt;condition_variable&gt;#include &lt;algorithm&gt;#include &lt;atomic&gt;#define debug(info) std::cout &lt;&lt; __LINE__ &lt;&lt; &quot; &quot; &lt;&lt; __func__ &lt;&lt; &quot;: &quot; &lt;&lt; info &lt;&lt; std::endl;template&lt;typename Task&gt;struct Result&#123; // 初始化为默认值 explicit Result() = default; // 当 Task 正常返回时用结果初始化 Result explicit Result(Task &amp;&amp;value) : _value(value) &#123; debug(&quot;Construct from value&quot;); &#125; // 当 Task 抛异常时用异常初始化 Result explicit Result(std::exception_ptr &amp;&amp;exception_ptr) : _exception_ptr(exception_ptr) &#123; debug(&quot;Construct from exception_ptr&quot;); &#125; // 读取结果，有异常则抛出异常 Task get_or_throw() &#123; if (_exception_ptr) &#123; std::rethrow_exception(_exception_ptr); &#125; return _value; &#125; private: Task _value&#123;&#125;; std::exception_ptr _exception_ptr;&#125;;template&lt;template&lt;typename&gt; class Task, typename R&gt;struct TaskAwaiter &#123; explicit TaskAwaiter(Task&lt;R&gt; &amp;&amp;task) noexcept : task(std::move(task)) &#123; debug(&quot;Construct from task&quot;); &#125; TaskAwaiter(TaskAwaiter &amp;&amp;completion) noexcept : task(std::exchange(completion.task, &#123;&#125;)) &#123; debug(&quot;Construct from completion&quot;); &#125; TaskAwaiter(TaskAwaiter &amp;) = delete; TaskAwaiter &amp;operator=(TaskAwaiter &amp;) = delete; constexpr bool await_ready() const noexcept &#123; debug(&quot;&quot;); return false; &#125; void await_suspend(std::coroutine_handle&lt;&gt; handle) noexcept &#123; debug(&quot;&quot;); std::cout &lt;&lt; handle.address() &lt;&lt; std::endl; // 当 task 执行完之后调用 resume task.finally([handle]() &#123; handle.resume(); &#125;); &#125; // 协程恢复执行时，被等待的 Task 已经执行完，调用 get_result 来获取结果 R await_resume() noexcept &#123; debug(&quot;&quot;); return task.get_result(); &#125; private: Task&lt;R&gt; task;&#125;;template&lt;template&lt;typename&gt; class Task, typename ResultType&gt;struct TaskPromise&#123; auto initial_suspend() noexcept &#123; debug(&quot;&quot;); return std::suspend_never&#123;&#125;; &#125; auto final_suspend() noexcept &#123; debug(&quot;&quot;); return std::suspend_always&#123;&#125;; &#125; Task&lt;ResultType&gt; get_return_object() &#123; return Task&#123;std::coroutine_handle&lt;TaskPromise&gt;::from_promise(*this)&#125;; &#125; void unhandled_exception() &#123; debug(&quot;&quot;); std::lock_guard lock(completion_lock); result = Result&lt;ResultType&gt;(std::current_exception()); completion.notify_all(); // 调用回调 notify_callbacks(); &#125; void return_value(ResultType value) &#123; debug(&quot;&quot;); std::lock_guard lock(completion_lock); result = Result&lt;ResultType&gt;(std::move(value)); completion.notify_all(); // 调用回调 notify_callbacks(); &#125; ResultType get_result() &#123; debug(&quot;from TaskPromise&quot;); // 如果 result 没有值，说明协程还没有运行完，等待值被写入再返回 std::unique_lock lock(completion_lock); if (!result.has_value()) &#123; debug(&quot;hasn&#x27;t value now&quot;); // 等待写入值之后调用 notify_all completion.wait(lock); &#125; else &#123; debug(&quot;already has value now&quot;); &#125; // 如果有值，则直接返回（或者抛出异常） return result-&gt;get_or_throw(); &#125; void on_completed(std::function&lt;void(Result&lt;ResultType&gt;)&gt; &amp;&amp;func) &#123; debug(&quot;&quot;); std::unique_lock lock(completion_lock); // 加锁判断 result if (result.has_value()) &#123; debug(&quot;already has value&quot;); // result 已经有值 auto value = result.value(); // 解锁之后再调用 func lock.unlock(); func(value); &#125; else &#123; debug(&quot;waiting for execution&quot;); // 否则添加回调函数，等待调用 completion_callbacks.push_back(func); &#125; &#125; // 注意这里的模板参数 template&lt;typename _ResultType&gt; auto await_transform(Task&lt;_ResultType&gt; &amp;&amp;task) &#123; debug(&quot;&quot;); return TaskAwaiter&lt;Task, _ResultType&gt;&#123;std::move(task)&#125;; &#125; private: // 回调列表，我们允许对同一个 Task 添加多个回调 std::list&lt;std::function&lt;void(Result&lt;ResultType&gt;)&gt;&gt; completion_callbacks; void notify_callbacks() &#123; debug(&quot;&quot;); auto value = result.value(); for (auto &amp;callback : completion_callbacks) &#123; debug(&quot;call callback function from completion_callbacks&quot;); callback(value); &#125; // 调用完成，清空回调 completion_callbacks.clear(); &#125; // 使用 std::optional 可以区分协程是否执行完成 std::optional&lt;Result&lt;ResultType&gt;&gt; result; std::mutex completion_lock; std::condition_variable completion;&#125;;template&lt;typename ResultType&gt;struct Task&#123; // 声明 promise_type 为 TaskPromise 类型 using promise_type = TaskPromise&lt;Task, ResultType&gt;; ResultType get_result() &#123; debug(&quot;from Task&quot;); return handle.promise().get_result(); &#125; Task &amp;then(std::function&lt;void(ResultType)&gt; &amp;&amp;func) &#123; debug(&quot;task id = &quot; + std::to_string(task_id)); std::cout &lt;&lt; handle.address() &lt;&lt; std::endl; handle.promise().on_completed([func](auto result) &#123; try &#123; func(result.get_or_throw()); &#125; catch (std::exception &amp;e) &#123; // 忽略异常 &#125; &#125;); return *this; &#125; Task &amp;catching(std::function&lt;void(std::exception &amp;)&gt; &amp;&amp;func) &#123; debug(&quot;task id = &quot; + std::to_string(task_id)); handle.promise().on_completed([func](auto result) &#123; try &#123; // 忽略返回值 result.get_or_throw(); &#125; catch (std::exception &amp;e) &#123; func(e); &#125; &#125;); return *this; &#125; Task &amp;finally(std::function&lt;void()&gt; &amp;&amp;func) &#123; debug(&quot;task id = &quot; + std::to_string(task_id)); std::cout &lt;&lt; handle.address() &lt;&lt; std::endl; handle.promise().on_completed([func](auto result) &#123; func(); &#125;); return *this; &#125; explicit Task(std::coroutine_handle&lt;promise_type&gt; handle) noexcept: handle(handle), task_id(cnt) &#123; ++cnt; debug(&quot;Construct from handle, task id = &quot; + std::to_string(task_id)); std::cout &lt;&lt; handle.address() &lt;&lt; std::endl; &#125; Task(Task &amp;&amp;task) noexcept: handle(std::exchange(task.handle, &#123;&#125;)), task_id(cnt) &#123; ++cnt; debug(&quot;Move Construct from task, task id = &quot; + std::to_string(task.task_id) &lt;&lt; &quot;-&gt;&quot; &lt;&lt; std::to_string(task_id)); std::cout &lt;&lt; handle.address() &lt;&lt; std::endl; &#125; Task(Task &amp;) = delete; Task &amp;operator=(Task &amp;) = delete; ~Task() &#123; if (handle) handle.destroy(); &#125; private: std::coroutine_handle&lt;promise_type&gt; handle; static std::atomic&lt;int&gt; cnt; const int task_id;&#125;;template &lt;typename T&gt;std::atomic&lt;int&gt; Task&lt;T&gt;::cnt = 0;Task&lt;int&gt; simple_task2() &#123; debug(&quot;task 2 start ...&quot;); using namespace std::chrono_literals; std::this_thread::sleep_for(1s); debug(&quot;task 2 returns after 1s.&quot;); co_return 2;&#125;Task&lt;int&gt; simple_task3() &#123; debug(&quot;in task 3 start ...&quot;); using namespace std::chrono_literals; std::this_thread::sleep_for(2s); debug(&quot;task 3 returns after 2s.&quot;); co_return 3;&#125;Task&lt;int&gt; simple_task() &#123; debug(&quot;task start ...&quot;); auto result2 = co_await simple_task2(); debug(&quot;returns from task2: &quot; + std::to_string(result2)); auto result3 = co_await simple_task3(); debug(&quot;returns from task3: &quot; + std::to_string(result3)); co_return 1 + result2 + result3;&#125;int main() &#123; auto simpleTask = simple_task(); std::cout &lt;&lt; &quot;======================&quot; &lt;&lt; std::endl; simpleTask.then([](int i) &#123; debug(&quot;simple task end: &quot; + std::to_string(i)); &#125;).catching([](std::exception &amp;e) &#123; debug(&quot;error occurred&quot; + std::string&#123;e.what()&#125;); &#125;); std::cout &lt;&lt; &quot;======================&quot; &lt;&lt; std::endl; try &#123; auto i = simpleTask.get_result(); debug(&quot;simple task end from get: &quot; + std::to_string(i)); &#125; catch (std::exception &amp;e) &#123; debug(&quot;error: &quot; + std::string&#123;e.what()&#125;); &#125; return 0;&#125; 运行结果分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110ASM generation compiler returned: 0Execution build compiler returned: 0Program returned: 0// 这里通过 auto simpleTask = simple_task(); 构建第一个 Task1 0x5562ea17feb0250 Task: Construct from handle, task id = 00x5562ea17feb0// 构建协程类第一步 initial_suspend100 initial_suspend: // 这里因为 suspend_never 所以继往下走295 simple_task: task start ...// 通过 auto result2 = co_await simple_task2(); 构建第二个 Task2 0x5562ea180fe0250 Task: Construct from handle, task id = 10x5562ea180fe0100 initial_suspend: 279 simple_task2: task 2 start ...282 simple_task2: task 2 returns after 1s.// 一直走到 co_return 2; 进入 TaskPromise::return_value126 return_value: // 通过 result = Result&lt;ResultType&gt;(std::move(value)); 用 value(2) 构建了一个 Result26 Result: Construct from value// 中间调了 completion.notify_all(); 但是这里没有 wait// 继续在 TaskPromise::return_value 中 notify_callbacks();181 notify_callbacks: // co_return 之后这个协程 0x5562ea180fe0 就结束了 (还没释放，因为 finial 是 suspend_always)105 final_suspend: // 这里把 co_return 的结果给到 Task1 的 TaskPromise170 await_transform: // await_transform 返回一个 TaskAwaiter, 把刚刚的 Task2 存起来了（移动拷贝）257 Task: Move Construct from task, task id = 1-&gt;20x5562ea180fe055 TaskAwaiter: Construct from task// 这里先判断 ready, 直接返回 false70 await_ready: // false 的情况下需要 suspend (注意这里传入的参数 handle 是 Task1 的 handle)76 await_suspend: 0x5562ea17feb0// 这里 task.finally([handle]() &#123; 就是刚刚存起来的 Task2// 传了一个回调去 handle.resume();241 finally: task id = 20x5562ea180fe0// handle.promise().on_completed([func](auto result) &#123; func(); &#125;);149 on_completed: // 这里判断了一下 result 有没有值, 那么这里因为是 Task2 的 Promise // 所以 result 在刚刚 return_value 填充上了153 on_completed: already has value// 这里是通过刚刚的回调调到的 Task1 Promise 的 handle.resume()87 await_resume: // 这里 return task.get_result(); 这里的 task 是刚刚传到 TaskAwaiter 的 Task2207 get_result: from Task136 get_result: from TaskPromise// 这里还是一样的 result 是 value(2)144 get_result: already has value now// 这里因为 TaskAwaiter 在 finally 中 resume 了 Task1 的 handle 所以继续进行297 simple_task: returns from task2: 2// 通过 auto result3 = co_await simple_task3(); 构建 Task3 0x5562ea180fe0250 Task: Construct from handle, task id = 30x5562ea180fe0// 后面 Task3 执行和返回的过程大部分都一样的100 initial_suspend: 287 simple_task3: in task 3 start ...290 simple_task3: task 3 returns after 2s.126 return_value: 26 Result: Construct from value181 notify_callbacks: 105 final_suspend: 170 await_transform: 257 Task: Move Construct from task, task id = 3-&gt;40x5562ea180fe055 TaskAwaiter: Construct from task70 await_ready: 76 await_suspend: 0x5562ea17feb0241 finally: task id = 40x5562ea180fe0149 on_completed: 153 on_completed: already has value87 await_resume: 207 get_result: from Task136 get_result: from TaskPromise144 get_result: already has value now// 一直到这里同样 Task1 通过 Task3 的回调被 resume 继续执行299 simple_task: returns from task3: 3// 这里 co_return 1 + result2 + result3; 调到 return_value126 return_value: // 这里和前面一样同样构建了 Result26 Result: Construct from value181 notify_callbacks: // 这里 Task 也走完了, suspend105 final_suspend: ======================// 刚刚所有的过程只在声明了 simpleTask 之后就执行完了// 接着调用 simpleTask.then()213 then: task id = 00x5562ea17feb0// 那这里同样之前已经有值了149 on_completed: 153 on_completed: already has value// 这里通过 on_completed 调回到 lambda 回调 debug(&quot;simple task end: &quot; + std::to_string(i));306 operator(): simple task end: 6// 这里 catch 了一下异常，但是因为没有异常所以没有触发 debug(&quot;error: &quot; + std::string&#123;e.what()&#125;);227 catching: task id = 0149 on_completed: 153 on_completed: already has value======================// try-catch 里的逻辑也类似207 get_result: from Task136 get_result: from TaskPromise144 get_result: already has value now313 main: simple task end from get: 6 References 渡劫 C++ 协程（4）：通用异步任务 Task","tags":["C++","Coroutine"]},{"title":"Ceph Client 中的 LRU 设计","path":"/posts/3763995770/","content":"在 Ceph 中 Client 和 MDS 部分的 lru 实现和淘汰策略稍有不同，但作用都是用来管理 dentry 等结构，方便及时将不使用的文件和目录清出内存，这里主要关注 lru 的实现而不关注 dentry 的淘汰时机。 首先看下 LRU 的结构： 1234567// lru.hclass LRU &#123;// ...private: using LRUList = xlist&lt;LRUObject*&gt;; LRUList top, bottom, pintail;&#125; 这里和大部分 LRU 的实现类似， ceph 也使用一个双向链表作为 lru 的基础结构（也就是这里的 xlist，基本可以当作一个双向链表看待）。只不过 ceph 同时使用了三个链表 top、bottom 和 pintail 来细化 lru 的不同位置。 其中 top 和 bottom 比较好理解就是一般 lru 实现中的首尾两端，越靠近 top.front() 则说明最近越多使用，越靠近 bottom.back() 则说明最近越少使用，可以被淘汰。 pintail 稍微特殊一点，在此链中的 dentry 表示正在有人使用（可能是外部应用持有文件的 filehandle，因此随时有可能访问），因此不会被 从 lru 链中淘汰，即使最近没有人使用。 123void lru_insert_top(LRUObject *o);void lru_insert_mid(LRUObject *o);void lru_insert_bot(LRUObject *o); 这里就对应将一个 lru object 插入 lru 链的三个位置（从外部看 lru 是一个链，内部才分为 top 或者 bottom），实际对应就是 123top.push_front(&amp;o-&gt;lru_link); // 将 object 插入 top 头部bottom.push_front(&amp;o-&gt;lru_link); // 将 object 插入 bottom 头部bottom.push_back(&amp;o-&gt;lru_link); // 将 object 插入 bottom 尾部，也是最接近淘汰的位置 另外之前已经说了 xlist 的实现属于是一个双向链表的变种，这里也简单看一下，以 top.push_front 为例： 1234void push_front(item *i) &#123; if (i-&gt;_list) i-&gt;_list-&gt;remove(i);// ... 首先就是如果这个 item（也就是一个 lru object） 已经在某一个链上了，那么先通过 remove 把这个 item 从先前的链上摘下来，这个实现可以避免一个 item 挂在多个链上 123// ... i-&gt;_list = this;// ... 接着将自己的 _list 指向 this，表示 item 的所属链表（也就是 top） 1234// ... i-&gt;_next = _front; i-&gt;_prev = 0;// ... 这里就是首先把 item 挂到链表上，因为是 push_front 所以 _prev 为空， _front 是整个链表的头部。 12345678// ... if (_front) _front-&gt;_prev = i; else _back = i; _front = i; _size++;\t&#125; 同时要更新一下链表的头尾指针，以及整个链表的长度。 接着，必要时 client 通过 lru_get_next_expire 获取最近最少使用的 object 进行 trim，这个过程实际上就是从 lru 中拿出 bottom.back() 12345678910LRUObject *lru_get_next_expire() &#123;\tadjust();\t// look through tail of bot\twhile (bottom.size()) &#123; LRUObject *p = bottom.back();\tif (!p-&gt;lru_pinned) return p;\t// move to pintail\tpintail.push_front(&amp;p-&gt;lru_link);&#125; 这里 adjust 就是把整个 lru 链中 object 数量的 60%（实际要减去 pinned object）放入 top，剩余部分放入 bottom 接着直接从 bottom 拿出末端 object，如果这个 object 没有 pinned 则直接将其返回，表示此 object 可以被 trim pin 和 unpin 则是一个特殊的过程， pin 一个指定的 dentry 时我们只需要将对应的 object 从 top 或者 bottom 上移出到 pintail 链上（无关乎首尾，因为 pintail 上的 dentry 都不能 trim），而 unpin 则只需要将其 pintail 中移出到 bottom 的尾部即可 整个 lru 设计相对来说比较容易理解，也非常易于使用。 对于一个特定的 dentry，我们会在初次获取到其 object 时可以将其放至 lru mid，初次使用时将其放至 lru top，接着如果没有使用会随着 lru 的 adjust 逐渐移动到 bottom 然后被 client 取出作为 expired object 淘汰掉，而如果这时通过 pin 加入 pintail 的话就会一直等到 unpin 之后再放到 bottom.back 等待 trim","tags":["Ceph"]},{"title":"C++20 Asio With Boost 获取 B 站徽章（直播间牌子）","path":"/posts/173569173/","content":"本文介绍了如何使用 C++20 with Asio (Boost 版本) 完成一个简单的客户端用于获取 B 站徽章。 强烈推荐昨天发现的一个视频 《Why C++20 is the Awesomest Language for Network Programming》，可以去油管上搜一下，总时长一个小时，比较长但是讲的很好，听的巨舒服，上次有这种感觉还是听那个 c10k 问题的视频。 总之先看一下程序执行的效果： 123➜ bili-medal git:(master) ./build/main &#123;my_cookie&#125;当前登录账号的 mid 为 29248492当前登陆账号所佩戴的直播间徽章为 &quot;ASAKI&quot;, 等级为 15 级 贴一下主要逻辑： 123456789101112131415161718192021222324252627282930313233343536373839404142awaitable&lt;void&gt; start(asio::io_context &amp;ctx, const std::string &amp;cookie)&#123; const std::string host = &quot;api.bilibili.com&quot;; // 解析域名 auto [e1, endpoint] = co_await tcp::resolver(ctx).async_resolve(host, &quot;https&quot;, use_nothrow_awaitable); // ssl_ctx 用于建立 https 连接 ssl::context ssl_ctx &#123;ssl::context::sslv23&#125;; ssl_socket socket &#123;ctx, ssl_ctx&#125;; static_assert(std::is_same_v&lt;std::decay_t&lt;decltype(socket.next_layer())&gt;, tcp::socket&gt;); // 建立 tcp 连接 ssl_ctx.set_default_verify_paths(); auto [e2, _] = co_await asio::async_connect(socket.lowest_layer(), endpoint, use_nothrow_awaitable); // https 握手，建立 https 连接 auto [e3] = co_await socket.async_handshake(ssl::stream_base::client, use_nothrow_awaitable); std::string mid; &#123; // 创建并发送一个 api 请求到 B 站服务器，获得返回结果并解析 mid 字段 auto request = make_request(http::verb::get, host, &quot;/x/web-interface/nav&quot;, cookie); auto response = co_await async_send_request(socket, request); auto data = json::parse(beast::buffers_to_string(response.body().data())); mid = data[&quot;data&quot;][&quot;mid&quot;].dump(); &#125; std::cout &lt;&lt; &quot;当前登录账号的 mid 为 &quot; &lt;&lt; mid &lt;&lt; std::endl; std::string medal_id, medal_name, medal_level; &#123; // 创建并发送一个 api 请求到 B 站服务器，获得返回结果并解析直播间徽章 auto request = make_request(http::verb::get, host, &quot;/x/space/acc/info?mid=&quot;+mid, cookie); auto response = co_await async_send_request(socket, request); auto data = json::parse(beast::buffers_to_string(response.body().data())); medal_id = data[&quot;data&quot;][&quot;fans_medal&quot;][&quot;medal&quot;][&quot;medal_id&quot;].dump(); medal_level = data[&quot;data&quot;][&quot;fans_medal&quot;][&quot;medal&quot;][&quot;level&quot;].dump(); medal_name = data[&quot;data&quot;][&quot;fans_medal&quot;][&quot;medal&quot;][&quot;medal_name&quot;].dump(); &#125; std::cout &lt;&lt; &quot;当前登陆账号所佩戴的直播间徽章为 &quot; &lt;&lt; medal_name &lt;&lt; &quot;, 等级为 &quot; &lt;&lt; medal_level &lt;&lt; &quot; 级&quot; &lt;&lt; std::endl;&#125; 整体流程我觉得是比较清晰的，基本上对 https 请求过程有所了解的话应该能容易能理解这里做了什么。 其中 async_resolve async_connect async_handshake 都是 Asio 提供的协程版本的异步函数，通过使用这些函数我们可以不必设置回调函数而是可以以同步方式书写代码，非常好用。 make_request 和 async_send_request 则是我们自己定义的两个函数，实现如下： 1234567891011121314151617181920212223http::request&lt;http::empty_body&gt; make_request(http::verb method, std::string host, std::string target, std::string cookie)&#123; http::request&lt;http::empty_body&gt; request; request.method(method); request.set(http::field::host, host); request.target(target); request.set(http::field::user_agent, BOOST_BEAST_VERSION_STRING); request.set(http::field::cookie, &quot;SESSDATA=&quot; + cookie); return request;&#125;awaitable&lt;http::response&lt;http::dynamic_body&gt;&gt; async_send_request(ssl_socket &amp;socket, http::request&lt;http::empty_body&gt; request)&#123; auto [e1, wbytes] = co_await http::async_write(socket, request, use_nothrow_awaitable); http::response&lt;http::dynamic_body&gt; response; beast::flat_buffer buffer; auto [e2, rbytes] = co_await http::async_read(socket, buffer, response, use_nothrow_awaitable); co_return response;&#125; 逻辑也比较简单，因为是 api 调用所以我们通过 async_write 发送请求之后直接通过 async_read 读取返回结果，注意这里的返回值 awaitable&lt;&gt; 是一个协程包装器类型，这使得我们的 async_send_request 函数实际成为了一个协程工厂，这样我们就可以通过 co_await 来调用了 另外对于返回的数据进行处理的部分则是使用了 nlohmann_json 完成 综上我们就实现了一个简单的客户端用于通过 cookie 获取用户所佩戴的直播间牌子的功能，这里可以看到我们实际上使用协程并不能够对程序的效率有多大的提高（单线程客户端，还是顺序执行的过程），但是更大的意义在于我们用同步方式写异步代码使得代码的可读性非常高，这是非常酷的一件事，在大型项目（尤其是服务端开发）中十分重要。","tags":["C++","Asio"]},{"title":"ChatGPT 注册教程","path":"/posts/3773623110/","content":"ChatGPT 推出已经有一段时间了，但是由于地区政策国内很多小伙伴都还没有能有机会区体验 AI 的魅力，这里就给大家介绍一下如何注册和使用 ChatGPT 前期准备要使用 ChatGPT, 你需要如下几样东西： 123- 一个科学且靠谱的上网办法- 一个邮箱用于接收验证码- 一个 Google 账号用于快速注册登录 (可选) 接着切换你的代理节点，尝试打开 ChatGPT 的登陆页面 如果你看到如下画面： 恭喜你此节点可以用于访问 ChatGPT，但如果 ChatGPT 提示 Access Deined,那就说明此节点被列入黑名单，需要换一个节点再试。 另外需要注意的一点是，尽量优先尝试使用非香港节点登录 ChatGPT 确认节点是否可用的原因是等下会用到一个接码平台用于注册 ChatGPT，要花几块钱，这里如果没有可用节点的话，等下充值甚至注册了没法用就很难受。 开始注册前期准备完成以后点击 Sign up 进入 ChatGPT 的注册页面，显示如下： 如果你恰好有一个 Google 账号，那么恭喜你，可以免去邮箱验证直接进入手机号验证环节，如果没有的话那就需要先验证邮箱 邮箱验证在 Email address 一栏中输入你的邮箱地址，点击 Continue，输入密码： 输入密码后继续点击 Continue ChatGPT 会提示你 Verify your email，这时你就可以打开你的邮箱点击 Verify email address 来验证了。 验证完成之后会提示你输入姓名，这里随便输一个就好： 接着 ChatGPT 会提示你需要绑定一个手机号 验证手机号邮箱验证完成或直接点击 Continue With Google 之后进入验证手机号的界面如下： 这里我们注意国内的手机号是不可用的，所以我们需要一个接码平台来接收验证码。 点击打开接码平台 sms-activate 的 &gt;&gt;&gt;主页面&lt;&lt;&lt; 并点击注册： 注意这里邮箱最好填 Gmail, 不行的话再填 QQ 邮箱，我自己第一次注册用的是 icloud 的一次性邮箱结果就没收到确认邮件。 查收邮件后点击确认即可，回到 sms-activate, 在右上角位置点击充值: 这一步之前是没有最小额度限制的，但是现在最少充 1 美元 (大概7块钱)，而我们注册 ChatGPT 只需要 3 块，剩下的钱你可以注册个什么其他账号玩一玩。 支付方式是支持支付宝的，直接扫码支付就可以。 接着到左边的搜索框中搜索 openai 并点击: 这里找一个最便宜的印尼就好了，点击右边的那个购物车（之前阿三貌似只要 15 卢布，用户多了以后涨价了） 接着 sms-activate 就会给你显示一个电话号码，有效期是 30 分钟，你就可以用这个电话返回到 ChatGPT 填入并点击 Send Code (注意点击国旗选择正确的国家和地区，印尼是 I 开头的) 如果这个时候 ChatGPT 提示你账号可疑不能发送验证码，那么没有关系，回到 sms-activate 点击手机号右边的叉取消订单（扣除的卢布会立即返还），然后再点击购物车图标重新换一个号码就好。 开始使用注册完成后在下方输入框输入你要说的话就可以和 ChatGPT 开始愉快的聊天了 &#x3D;v&#x3D; 你可以用它来辅助学习： 不过以我这段时间的经验来看， ChatGPT 只能是做到一个辅助的作用，由于数据集过于庞大和复杂，在涉及到一些比较复杂的问题时 ChatGPT 会混淆不同版本实现的差异甚至自己创造一些源码里不存在的函数和变量（说人话就是一本正经的跟你胡说八道），比如下面这样： 我猜 ChatGPT 可能是日裔（ 祝大家玩的开心！","tags":["Other"]},{"title":"如何向 STL 算法中传入重载函数","path":"/posts/781272769/","content":"本文分享如何向 STL 算法中传入重载函数，来自 Jonathan 2017 年在 Fluent C++ 上发起的一个挑战 123The STL is a fantastic tool to make your code more expressive and more robust. If you’re a C++ developer and want to become proficient, it is essential that you learn the STL.But there is one case where we can’t apply STL algorithms right out of the box: when the function passed has overloads. 大概意思是说 STL 本身非常好用，但是如果传递一个具有重载的函数就会使得 STL 失效。 举个例子，如果我们定义了一个函数 func 以及一个 vector 数组如下： 12345void func (int &amp;i) &#123; ++i;&#125;std::vector&lt;int&gt; numbers = &#123;1, 2, 3, 4, 5&#125;; 那么我们可以通过 for_each 使 numbers 中的每个数字加一： 1std::for_each(begin(numbers), end(numbers), func); 但是这时如果我们还有一个同名的重载函数： 1void func (std::string &amp;s); 就会导致刚刚的代码编译失败, 因为编译器无法推断我们要使用哪一个版本： 1234567main.cpp: In function &#x27;int main()&#x27;:main.cpp:20:50: error: no matching function for call to &#x27;for_each(std::vector&lt;int&gt;::iterator, std::vector&lt;int&gt;::iterator, &lt;unresolved overloaded function type&gt;)&#x27; std::for_each(begin(numbers), end(numbers), func); ^/usr/local/include/c++/7.1.0/bits/stl_algo.h:3878:5: note: template argument deduction/substitution failed:main.cpp:20:50: note: couldn&#x27;t deduce template parameter &#x27;_Funct&#x27; std::for_each(begin(numbers), end(numbers), func); 这时我们只能通过指定 func 的类型来避免这个错误： 1std::for_each(begin(numbers), end(numbers), static_cast&lt;void(*)(int&amp;)&gt;(func)); 这显然并不美观，也会使得代码的可读性下降，于是 Jonathan 希望大家能够用更好的方式来解决这个问题不知道大家现在是否有自己的想法呢,如果你也想挑战一下这个问题，不妨暂停一下，来一个简单的头脑风暴，说不定你的方案更加优秀。 倒计时 3 2 1 答案揭晓！ 首先说一下我个人的想法，我的想法非常简单，首先这里编译报错是因为 for_each 函数无法判断这里所用到的 func 应该使用哪一个版本，即使这对我们来说非常直观 (容器内是 int 那么就应该调用 int 版本的重载，string 亦然)。 那么为了帮助确定重载版本，我们可以使用一个 lambda 函数代替 func 作为 for_each 的处理函数，而 lambda 的实现方式允许我们拿到 处理的参数类型并进一步确定所调用的 func 版本 1std::for_each(begin(numbers), end(numbers), [](auto i)&#123; return func(i); &#125;); 如果你的想法也和我一样，恭喜你也同时了 Jonathan 的称赞，他评价这种解决方案 It’s not as generic as the the previous solution, but it does all that is necessary for simple cases这并非通用的解决方案，但它能很好的胜任大多数不复杂的场景 接下来让我们看一下本次挑战的最终获胜答案，来自 Vittorio Romeo: 1234567// C++ requires you to type out the same function body three times to obtain SFINAE-friendliness and// noexcept-correctness. That&#x27;s unacceptable.#define RETURNS(...) noexcept(noexcept(__VA_ARGS__)) -&gt; decltype(__VA_ARGS__)&#123; return __VA_ARGS__; &#125;// The name of overload sets can be legally used as part of a function call - we can use a macro to// create a lambda for us that &quot;lifts&quot; the overload set into a function object.#define LIFT(f) [](auto&amp;&amp;... xs) RETURNS(f(::std::forward&lt;decltype(xs)&gt;(xs)...)) 怎么样，你的脑袋有没有被‘轻轻敲醒’的感觉，反正与我而言乍一看这段代码直接就是一个当头棒喝。不过当你沉下心一点点分析这段代码，你就会越来越被这代码里精妙的设计吸引。 为了理解这部分代码，我们可以先尝试对 LIFT(func) 进行展开，结果如下: 1234[](auto&amp;&amp;... xs) noexcept(noexcept(func(::std::forward&lt;decltype(xs)&gt;(xs)...))) -&gt; decltype(func(::std::forward&lt;decltype(xs)&gt;(xs)...))&#123; return func(::std::forward&lt;decltype(xs)&gt;(xs)...);&#125; 怎么样,是不是突然就有了一种熟悉的感觉。没错，其实这也是一个 lambda 函数，只是相比于我们的简略版本考虑的更多的情况，接下来让我们一点一点分析。 1234[] (auto&amp;&amp;... xs) /*省略*/&#123; return func(::std::forward&lt;decltype(xs)&gt;(xs)...);&#125; 除开省略部分我们可以看到就是一个完美转发并支持变长参数，这使得 LIFT 可以适用于多个参数的函数并且不改变其传入参数的类型。 接着看省略部分，也就是 RETURNS 部分的内容: 12/*省略*/ noexcept(noexcept(func(::std::forward&lt;decltype(xs)&gt;(xs)...))) -&gt; decltype(func(::std::forward&lt;decltype(xs)&gt;(xs)...))/*省略*/ 包含两部分内容 noexcept(...) 和 -&gt; decltype(...): 后者指定了 LIFT 的返回类型，在我们的简单方法中没有指定，因此默认会使用 -&gt; auto，这可能会使得由 func 返回的值类型被改变，考虑如下示例： 123456789101112131415161718192021222324252627282930int&amp; func_return_value (int&amp; i) &#123; return i;&#125;void use_value(int&amp; i) &#123; std::cout &lt;&lt; &quot;I got a l value i:&quot; &lt;&lt; i &lt;&lt; &amp;i &lt;&lt; std::endl;&#125;void use_value(int&amp;&amp; i) &#123; std::cout &lt;&lt; &quot;I got a r value i:&quot; &lt;&lt; i &lt;&lt; &amp;i &lt;&lt; std::endl;&#125;auto x = [](auto&amp;&amp;... xs) &#123; return func_return_value(::std::forward&lt;decltype(xs)&gt;(xs)...);&#125;;auto x1 = [](auto&amp;&amp;... xs) -&gt; decltype(func_return_value(::std::forward&lt;decltype(xs)&gt;(xs)...))&#123; return func_return_value(::std::forward&lt;decltype(xs)&gt;(xs)...);&#125;;auto main(void) -&gt; int &#123; int a = 3; // I have a value a :30x7ffc9ecd766c std::cout &lt;&lt; &quot;I have a value a :&quot; &lt;&lt; a &lt;&lt; &amp;a &lt;&lt; std::endl; // I got a r value i:30x7ffc9ecd76ac use_value(x(a)); // I got a l value i:30x7ffc9ecd766c use_value(x1(a));&#125; 对示例来说我们希望拿到并传入由 func_return_value 返回的 int&amp; 类型变量，但是由于 x 中的默认返回类型为 auto，因此导致其示例化了一个新的临时变量并作为右值返回。 接着思考另外一个问题，如果我们使用 -&gt;decltype(auto) 代替 -&gt;auto 呢，是否可以达到我们想要的目标, 又会有什么问题呢。 Jonathan 也帮助我们分析了这一问题，并指出 decltype(expr) 的版本具有更好的 SFINAE 亲和性, Guillaume Racicot 在 stackoverflow 上也讨论了这个问题。 实际上结合 Vittorio 在 C++Now 2017 的演讲，我更偏向于这里使用 -&gt;decltype(auto) 也能同样出色的完成任务，但是 RETURNS 中的用法可以带给我们再其他更多场景下使用的启发。 接着 LIFT 的最后一部分 noexcept 则是根据传入的 func 设置是否抛出异常 综上，希望大家能够收获一点有用的东西！ References: Can You Wield C++ Function Overloading Like Jon Snow Wields Longclaw?","tags":["C++"]},{"title":"RAC 集群访问过程分析","path":"/posts/4037772901/","content":"本文介绍了通过 WireShark 分析的在 RAC11gR2 集群访问中连接建立的过程 环境 环境： 主机：192.168.40.37 SCAN节点：192.168.40.234 节点1：192.168.40.230 vip：192.168.40.231 节点2：192.168.40.232 vip：192.168.40.233 连接过程 主机与scan节点进行三次握手，建立tcp连接（目的端口1521） 主机向scan节点发送Oracle-TNS（Transparent Network Substrate Protocol）Request，主要携带信息如下： 1234567891011121314Packet Type: Connect (1)Connect Version: 314 Service Options: 0x0041 Session Data Unit Size: 8192 Maximum Transmission Data Unit Size: 32767 NT Protocol Characteristics:0xc60e, Hangon to listener connect, Confirmed release, Callback IO supported, ASync IO Supported, Generate SIGURG signal, Urgent IO supported, Full duplex IO supported Value of 1 in Hardware: 0100 Connect Flags 0:0x41, NA services wanted Connect Flags 1:0x41, NA services wanted Trace Cross Facility Item 1: 0x00000000 Trace Cross Facility Item 2: 0x00000000 Trace Unique Connection ID: 0x0000000000000000 Connect Data: (DESCRIPTION=(CONNECT_DATA=(SERVICE_NAME=MER)(CID=(PROGRAM=E:\\Navicat?for?Oracle avicat.exe)(HOST=DESKTOP-PSOJPQF)(USER=MER)))(ADDRESS=(PROTOCOL=tcp)(HOST=192.168.40.234)(PORT=1521))) scan返回TNS Response, Redirect消息 scan返回TNS Response, Data，包含指示主机需要请求的host信息，同时填充了要访问的实例名： 1234567Data Data Flag:0x0040, End of File Data Data: (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.40.231)(PORT=1521))) (DESCRIPTION=(CONNECT_DATA=(SERVICE_NAME=MER)(CID=(PROGRAM=E:\\Navicat?for?Oracle avicat.exe)(HOST=DESKTOP-PSOJPQF)(USER=MER))(SERVER=dedicated)(INSTANCE_NAME=mer1))(ADDRESS=(PROTOCOL=tcp)(HOST=192.168.40.234)(PORT=1521))) Length: 293 主机与Scan进行四次挥手，断开tcp连接 主机向重定向节点，此处为节点1（vip）发起tcp连接 主机向节点1发送Connect消息，携带信息如下，此处的请求信息同scan返回响应一致（目的端口1521）： 1(DESCRIPTION=(CONNECT_DATA=(SERVICE_NAME=MER)(CID=(PROGRAM=E:\\Navicat?for?Oracle avicat.exe)(HOST=DESKTOP-PSOJPQF)(USER=MER))(SERVER=dedicated)(INSTANCE_NAME=mer1))(ADDRESS=(PROTOCOL=tcp)(HOST=192.168.40.234)(PORT=1521))) 节点1返回Accept 协商安全协议 协商数据类型 传输数据（用户名密码的验证是在这一部分做的）","tags":["Oracle RAC","Database"]},{"title":"Windows7 下安装 Oracle RAC11gR2","path":"/posts/324638463/","content":"本文介绍了如何在 Window7 环境下安装 Oracle RAC11gR2 的方法以及安装过程中遇到的一些问题的解决方法 资源 win64_11gR2_grid win64_11gR2_database_1of2 win64_11gR2_database_2of2 以上资源可在官网下载 安装文档以 Rac11gR2OnWindows.pdf 为准，由于文档上面有很多步骤比较省略，且更接近真实环境下的配置方案，因此找了 一篇安装步骤非常接近官方文档的博客1作为参考，同时结合其他博客进行安装 首先给出网络拓扑结构如下，后面遇到问题可以返回来作为参照 正式开始配置 配置步骤虚拟机准备 创建一个 Windows7 虚拟机（使用 VMware® Workstation 15 pro） 安装 jdk （版本应在 1.5 及以上） 为虚拟机添加一块网卡 克隆虚拟机 ✴︎节点名称配置修改主机名、统一用户名密码，分别更改两台服务器的主机名为 cluster1 和 cluster2，需要重启后生效，两台服务器统一使用 administrator 用户，并且保持密码一致。 修改主机名在“资源管理器-&gt;右键（计算机）-&gt;属性-&gt;更改设置（计算机名称、与和工作组）-&gt;更改“，保存后重启即可 用户必须使用 administrator 用户，需要在“资源管理器-&gt;右键（计算机）-&gt;管理-&gt;本地用户和组“中开启并设置密码 对所有节点执行上述操作，保证各节点 administrator 账户的密码相同，后续操作同样需要在 administrator 账户下进行，重启后注意切换用户 配置本地安全策略 运行 secpol.msc ,配置”安全设置-&gt;本地策略-&gt;安全选项-&gt;用户帐户控制:管理员批准模式中管理员的提升权限提示的行为”为”不提示，直接提升”。 确认”安全设置-&gt;本地策略-&gt;用户权限分配-&gt;管理审核和安全日志”中包括 Administrators 组。 运行 firewall.cpl ,关闭防火墙。 关闭防火墙需要在 “cmd-&gt;firewall.cp-&gt;高级设置-&gt;防火墙属性” 中确定防火墙状态为关闭 测试 net use在每个节点执行 net use \\\\remote node name\\C$ 提示命令成功完成则正确，否则不正确 &gt;&gt;执行net use失败&lt;&lt; 远程注册表连接测试运行 regedit ,选择 “文件-&gt;连接网络注册表-&gt;输入远程节点nodename” 出现注册表结构树,测试成功.(所有节点执行) ✴︎配置网络 在“网络和共享中心-&gt;更改适配器设置”中将网络适配器的名称改为”net0”和”net1” 按照拓扑图修改ip地址（net0为公网，net1为私网） 示例： cluster1： net0 -&gt; Public IP: 192.168.40.230&#x2F;24 net1 -&gt; Private IP: 10.0.0.95&#x2F;24 cluster2: net0 -&gt; Public IP: 192.168.40.232&#x2F;24 net1 -&gt; Private IP:10.0.0.97&#x2F;24 在“网络和共享中心-&gt;更改适配器设置-&gt;（按下alt）高级-&gt;高级设置”中修改连接顺序为net0-&gt;net1-&gt;… 修改hosts文件：位于C:\\Windows\\System32\\drivers\\etc 示例： #public 192.168.40.230 cluster1 192.168.40.232 cluster2 #private 10.0.0.95 cluster1-priv 10.0.0.97 cluster2-priv #vip 192.168.40.231 cluster1-vip 192.168.40.233 cluster2-vip #scan 192.168.40.234 cluster-scan 使用ping验证hosts文件修改是否成功 关闭DHCP媒体感知打开注册表定位到 HKLM\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters 子项,新建一个 DWORD 类型的键值 DisableDHCPMediaSense ,将值修改为 1. 重启后使用命令 netsh interface ipv4 show global 验证是否成功关闭. 关闭SNP Features12C:\\&gt;netsh int tcp set global chimney=disabledC:\\&gt;netsh int tcp set global rss=disabled 重启后使用命令 C:\\&gt;netsh interface ipv4 show global 验证是否成功关闭 停止MSDTC服务运行 services.msc ,将 Distributed Transaction Coordinator (MSDTC) 服务停止,并设为”手动”. 同步节点时间1、运行 Regedit 定位到 HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\W32Time\\Config 子项,将主键 MaxNegPhaseCorrection 数值修改为0,关闭注册表程序. 执行同步: C:\\&gt;W32tm /config /update (需要连接Internet) 2、或者：在 RAC2 服务器上运行命令：net time \\rac1 (查看 RAC1 的当前时间)然后在 RAC2 服务器上运行命令：net time \\rac1 /set /y (设置 RAC2 时间与 RAC1 同 步)（建议使用这种方式） 检查环境变量计算机 右键-&gt;属性-&gt;高级系统设置-&gt;环境变量,确认变量TMP和TEMP值相同. 配置 DEP 和 UAC1、分别配置两台服务器上的数据执行保护（DEP），选择‘仅为基本 windows程序和服务启用’，需要重启后才能生效（可配置完下一步后一起重启） 确认两台服务器上的 UAC，若需要配置则在重启后生效(默认不需要配置) 修改虚拟内存由于服务器的内存为 16G，按照 Oracle 的官方文档，虚拟内存至少为实际内 存的 2 倍，此处选择在本地磁盘一个较大的空白分区（E 盘）中划分了虚拟 内存，取值范围：32G~64G，即初始值：32768MB，最大值：65536MB ✴︎配置共享磁盘 这一步与使用的虚拟机及其版本有关，这里使用的是VMware® Workstation 15 pro，使用其他如VirtualBox请自行搜索配置方式 在虚拟机中添加2块磁盘分别用作OCR_VOTE（表决磁盘）以及DATA（数据磁盘）： 虚拟磁盘类型：SCSI(S) →创建新的虚拟磁盘（第一次创建，之后使用现有的虚拟磁盘） →磁盘大小（OCR：4G，DATA：16G，FRA：8G（如果有））、立即分配、存储为单个文件 在“虚拟机设置→选中硬盘→高级”中将新添加的虚拟设备节点按照顺序设为SCSI 1:x 在其他节点中添加相同数量的虚拟磁盘，并将设备节点一一对应设置 打开虚拟机文件（xxx.vmx）添加如下行（注意删除已存在的重复行）： 1234567891011disk.locking=&quot;FALSE&quot;disk.EnableUUID = &quot;TRUE&quot;diskLib.dataCacheMaxSize = &quot;0&quot;diskLib.dataCacheMaxReadAheadSize = &quot;0&quot;diskLib.dataCacheMinReadAheadSize = &quot;0&quot;diskLib.dataCachePageSize = &quot;0&quot;diskLib.maxUnsyncedWrites = &quot;0&quot;scsi1.shared=&quot;TRUE&quot;scsi1.virtualDev = &quot;lsilogic&quot;scsi1.sharedBus = &quot;VIRTUAL&quot;scsi1.present = &quot;TRUE&quot; 并在克隆的虚拟机vmx文件中额外添加如下行（取决于磁盘数量）： 123scsi1:0.mode = &quot;independent-persistent&quot;scsi1:1.mode = &quot;independent-persistent&quot;... 配置完成后重新打开“虚拟机设置”中可以看到克隆机显示磁盘为（独立） &gt;&gt;可能存在的问题&lt;&lt; 开机，在“计算机→（右键）管理→磁盘管理”中可以看到刚刚添加的磁盘，同时会提示需要对磁盘进行初始化（没有弹出提示的话可以手动全部选中，点击右键→初始化磁盘），并选择使用GPT初始化 为每一个节点执行上一步操作 为每一块磁盘选择“右键→新建简单卷→不分配驱动器号或驱动器路径→不要格式化这个卷“ 完成后应该显示磁盘为RAW设备 在另一台虚拟机上打开磁盘管理重新扫描磁盘即可 &gt;&gt;共享磁盘显示不正确&lt;&lt; 启用Automount (All Nodes)进行命令行窗口,运行: 12C:\\&gt; diskpartDISKPART&gt; AUTOMOUNT ENABLE 标记ASM磁盘在cluster1执行以下命令（cd至 grid安装目录\\asmtool） 1E:\\grid\\asmtool&gt;asmtoolg.exe 在弹出的图形化界面中进行以下操作： 选择“Add or change label“ →选中作为表决磁盘的虚拟硬盘 →修改下方标记为“OCR” →点击下一步 这一步只需在cluster1节点下操作，并且此时只标记OCR磁盘组，用于DATA组的硬盘暂不处理 ✴︎安装Grid Infrastructure (cluster1)执行预检查 D:\\11\\grid&gt;runcluvfy stage -pre crsinst -n rac1,rac2 -verbose 如果有报错,检查修改前面的设置直到预检查成功 在grid目录下执行setup.exe程序 选择“跳过软件更新” 选择‘为集群安装和配置 集群的网络基础结构’ 选择‘高级安装’ 选择安装语言 填写集群名称和 SCAN 名称，必须填写 hosts 文件中 SCAN IP 对应的主机名,确认去掉“配置GNS”复选框。 示例： 集群名称：mer-cluster scan名称：cluster-scan scan端口：1521 添加其他节点（应当显示cluster1和cluster2） 更改网络接口类型，默认选项如果不对，需要手动更改 此处选择‘自动存储管理（ASM） 选择相应的OCR磁盘组，并输入磁盘组名称OCR 示例： 磁盘组名：OCR 冗余：外部 添加磁盘：候选磁盘（选择标记为OCR的磁盘路径） 添加 ASM （ASMSnmp）口令（topsec） 由于设置的密码不符合标准，需要确认来强制使用 此处选择‘不使用 IPMI 选择软件相关目录 示例： Oracle基目录：C:\\app\\Administrator 软件位置：C:\\app\\11.2.0\\grid 先决条件检查，如果检查通过，则出现概要，如果提示失败，会有相应的提示，请根据提示 检查之前步骤中的设置是否存在问题 开始安装后，会在”网格基础结构配置“处停顿较长时间，此处也是 grid 安装成功与否的关键所在，如果此处出现问题，则需要 卸 载 grid，并检查之前所有的设置，然后再次尝试安装，直到显示成功为止。 安装成功完成 检查ora.asm资源运行状态grid 安装完成后，如果安装成功，可在 dos 环境下通过 crs_stat –t –v 命令或者 crsctl status res -t 查看集 群启动了哪 些服务 ✴︎安装RDBMS（cluster1）执行预检查 D:\\grid&gt;runcluvfy stage -pre dbinst -n rac1,rac2 -verbose 开始安装 执行database目录下setup.exe程序 确认跳过‘指定电子邮件地址 选择“跳过软件更新” 选择‘仅安装数据库软件 查看节点名称是否正确 选择安装语言 选择安装企业版，并且勾选所有组件 选择安装路径 示例： Oracle基目录：C:\\app\\Administrator 软件位置：C:\\app\\Administrator\\product\\11.2.0\\db_home1 先决条件检查 安装概要 安装到此处时，执行远程安装 RAC2 节点的数据库，此时等待时间会很长， 请耐心等待 ✴︎安装完成后需要根据提示在cluster2节点上执行操作（注意别随手关闭提示） C:\\app\\Administrator\\product\\11.2.0\\dbhome_1\\BIN\\selecthome.bat 执行过程中出现的计数器尚未安装可以忽略 &gt;&gt;安装RDBMS失败（不要关闭提示窗口）&lt;&lt; 使用ASMCA创建ASM磁盘组 在命令行下执行asmca 在磁盘组选项卡中点击新建 单击在磁盘上加载标记 参考标记OCR的方式标记DATA磁盘 标记完成后填写磁盘组为DATA，冗余为外部，选择标记的磁盘，点击确定 创建磁盘组 按照相同的方法标记和创建 FRA 磁盘组（有需要的话） 创建完成后退出. ✴︎创建数据库执行预检查 D:\\grid&gt;runcluvfy stage -pre dbcfg -n all -d D:\\app\\Administrator\\product\\11.2.0\\db1 创建数据库 D:\\&gt;dbca &gt;&gt;找不到dbca命令&lt;&lt; 选择RAC数据库 选择创建数据库 一般用途或事务处理 配置数据库标示 示例： 配置类型：管理员管理的 全局数据库名：mer SID前缀：mer 单击全选 配置管理选项 示例： 勾选配置Enterprise Manager 选择配置Database Control进行本地管理 不勾选预警通知与每日备份 对所有账户使用同一管理口令 使用Oracle-Managed Files，选择数据库区为刚刚标记的DATA磁盘组 输入之前设置的ASM口令 取消勾选快速恢复区 配置字符集→从字符集列表中选择→”ZHS16GBK - GBK16位简体中文“ 数据库存储 创建数据库 数据库概要 等待创建完成 &gt;&gt;数据库创建失败&lt;&lt; 数据库创建完成中可能弹出提示如下: 此时按照提示在相应节点上（此处为cluster2）执行命令： 首先确定dbconsole状态： ​ C:\\&gt;emctl status dbconsole 若显示：Environment variable ORACLE_UNQNAME not defined. Please define it. 则设置环境变量ORACLE_UNQNAME: ​ C:\\&gt;set ORACLE_UNQNAME&#x3D;mer 若提示其他（如sid）未定义，则也设置相应的值 之后执行提示的第二步命令： ​ C:\\…\\db_home\\bin\\emctl.bat start dbconsole 执行完毕后回到cluster1节点点击确定提示集群数据库创建完成，并返回管理url 点击口令管理，解锁scott账户，设定密码 至此集群安装完成，在web端输入db control url即可访问管理登录界面，使用 用户名：SYSTEM 密码：topsec（之前设置的统一管理密码） 即可登录到集群管理界面 &gt;&gt;登录失败&lt;&lt; 可能遇到的问题及解决方法1、执行net use失败 错误号5，拒绝访问：很可能你使用的用户不是管理员权限的，先提升权限；错误号51，Windows无法找到网络路径：网络有问题；错误号53，找不到网络路径：ip地址错误；目标未开机；目标lanmanserver服务未启动；目标有防火墙（端口过滤）；错误号67，找不到网络名：你的lanmanworkstation服务未启动或者目标删除了ipc$；错误号1219，提供的凭据与已存在的凭据集冲突：你已经和对方建立了一个ipc$，请删除再连；错误号1326，未知的用户名或错误密码：原因很明显了；错误号1792，试图登录，但是网络登录服务没有启动：目标NetLogon服务未启动；错误号2242，此用户的密码已经过期：目标有帐号策略，强制定期要求更改密码； 确定当前登录用户为administrator 确定已为administrator用户设定密码 执行net share确定包含C$ 在”Windows+R”中执行secpol.msc，确定“安全设置→本地策略→安全选项”中“网络访问：本地账户的共享和安全模型”设置为“经典：对本地用户…“ 2、vmx文件中可能存在的问题 在多数的博客中，设置disk.EnableUUID与scsi1.virtualDev的值为如下 12disk.EnableUUID = &quot;TRUE&quot;scsi1.virtualDev = &quot;lsilogic&quot; 但在少数博客中将这个值设置（或保持原来的值）为 12disk.EnableUUID = &quot;FALSE&quot;scsi1.virtualDev = &quot;lsisas1068&quot; 经测试这两种值似乎不影响共享磁盘的效果，但这里仍旧推荐使用第一种的配置值 3、共享磁盘显示不正确 检查是否所有节点都显示磁盘以联机，尝试重新配置 4、安装RDBMS失败 预检查成功，但安装时提示对于节点磁盘空间的先决检查失败 可以忽略该问题，对后续安装过程不造成影响 安装中途cluster2死机或重启导致安装中断 暂时不要关闭提示窗口，重启cluster2并切换至administrator账户，等待至集群服务启动后（各vip、scan-ip可以ping通）返回cluster1点击确定可以继续安装 所选安装与指定 Oracle 主目录中已安装的软件冲突 的问题 正确的做法是卸载RDBMS，清除相关文件、注册表以及服务并重新安装，但是没有找到相关的文档，删除所有Oracle项又会对以安装的grid项造成影响，因此此处选择修改数据库软件安装路径，将dbhome_1修改为dbhome_2，修改后可能会出现“无法启动&#x2F;关闭&#x2F;找到指定路径 OracleMTSRecoveryService”，解决方法同下 OracleMTSRecoveryService 无法启动&#x2F;关闭&#x2F;找到指定路径 首先打开Win+R，“（输入）services.msc→（找到）OracleMTSRecoveryService “，若该服务不存在则不适用于下述解决方法，初次安装时提示无法启动不适用 确定该服务存在并确定其启动类型为自动后，打开Win+R，“（输入）regedit→（找到）HKEY_LOCAL_MACHINE→SYSTEM→CurrentControlSet→services→OracleMTSRecoveryService”，修改ImagePath的值为新的安装路径（dbhome_2），并对以下位置进行同样的修改： HKEY_LOCAL_MACHINE→SYSTEM→CurrentControlSet→services→OracleMTSRecoveryService HKEY_LOCAL_MACHINE→SYSTEM→ControlSet001→services→OracleMTSRecoveryService HKEY_LOCAL_MACHINE→SYSTEM→ControlSet002→services→OracleMTSRecoveryService 其他节点的对应位置 修改完成后点击确定关闭提示窗口继续安装 若是初次安装时提示无法启动OracleMTSRecoveryService服务，则在cluster2节点打开Win+R，“（输入）services.msc→（找到）OracleRemExecService “，若ImagePath中的路径在Temp后有两个\\，则删除后刷新注册表（重启explorer）,返回cluster1节点点击重试即可 5、数据库创建失败 ‘dbca’ 不是内部或外部命令，也不是可运行的程序或批处理文件： 重启cmd，若仍找不到命令请确定RDBMS安装正确 配置em失败，提示如下： 该问题未知明确的解决流程，首先尝试重新运行dbca，若再次失败则按照提示运行使用emca脚本，命令为 emca -config dbcontrol db -repos create 按照提示输入 确定后可能提示实例不存在或其他错误，返回重新执行dbca，若依旧失败需自行寻找解决办法 已明确的： ​ 不需要配置监听程序，即使查看监听程序不存在 ​ 此时emca执行失败是正常的，create或是recreate ​ 大概率在emca失败后重新执行dbca可以解决该问题（可能的原因，emca执行过程中创建了监听器等dbca所需的环境） 6、登录失败 若确定用户名&#x2F;密码正确，尝试重启cluster 重启后执行crsctl check crs，确定连接正常后再行尝试登录 若依旧失败尝试使用以下命令（administrator账户下） 12345678（1）以sysdba身份登录，不需要提供用户名和密码。 sqlplus /as sysdba ; （2）为用户解锁。alter user system account unlock;（3）重新设定密码。alter user system identified by system123456; 更多任何情况下提示如下问题时： CRS-4639：无法连接 Oracle 高可用性服务，ohasd.bin 未运行或 ohasd.bin 虽在运行但无 init.ohasd 或其他进程 CRS-4530：联系集群同步服务守护进程时出现通信故障，ocssd.bin 未运行 CRS-4535：无法与集群就绪服务通信，crsd.bin 未运行 请检查crsctl check crs是否返回对应服务正常，若刚重启节点，请等待一段时间，否则请重启节点再试 安装完成后的检查项： 123456789crs_stat -t -vsrvctl status listener -n cluster1srvctl status listener -n cluster2srvctl config database -d mersrvctl status database -d mer 参考 RAC11gR2OnWindows.pdf Oracle 11G RAC For Windows 2008 R2部署手册（亲测，成功实施多次） Oracle11gR2 RAC for Windows安装上篇 在安装oracle 11g时，出现执行先决条件失败的情况如下 oracle下system用户解锁和改密码 EM Express不起作用的故障排除 (Doc ID 1604062.1) 监听程序未启动或数据库服务未注册到该监听程序解决方法 net use访问远程电脑 ASM磁盘、目录的管理 安装oracle 11g时出现启动服务出现错误，找不到OracleMTSRecoveryService 以sysdba身份登录oracle报ORA-1031权限不足错误之完美分析 Oracle中sqlplus登录报错SP2-0667和SP2-0750探究","tags":["Oracle RAC","Database"]},{"title":"Nginx 多阶段 Http 请求处理流程","path":"/posts/649054200/","content":"Nginx 通过将各个阶段的所有模块按序的组织成一条执行链，以流水线的形式依次进行处理。 执行链及流程nginx执行链的定义如下： 12345typedef struct &#123; ngx_http_phase_handler_t *handlers; /*执行链*/ ngx_uint_t server_rewrite_index; ngx_uint_t location_rewrite_index;&#125; ngx_http_phase_engine_t; 执行链节点的数据结构定义如下： 12345struct ngx_http_phase_handler_s &#123; ngx_http_phase_handler_pt checker; ngx_http_handler_pt handler; ngx_uint_t next;&#125;; 对于执行链节点，相同阶段具有相同的checker函数，handler中则保存的是挂载至该阶段的模块处理函数，一般在checker函数中会执行当前节点的handler函数 执行链的执行流程是按照执行链顺序向前执行，但某个阶段需要回跳或跳过之后的某些执行阶段，next字段保存的就是跳跃的目的索引。 各个阶段如下： NGX_HTTP_POST_READ_PHASE 接受完请求头之后的第一个阶段，位于uri重写之前，默认情况下该阶段被跳过; nginx源码中仅有realip模块在POST_READ阶段对客户端ip进行了替换，且该模块并未被默认编译进nginx POST_HEAD阶段的checker函数仅调用对应的handler函数，随后对返回值进行处理，当handler返回NGX_OK时进入下一阶段 NGX_HTTP_SERVER_REWRITE_PHASE server级别的uri重写阶段，执行于server块内，location块外的重写指令。 nginx的rewrite模块在此阶段提供url重写指令rewrite和变量指令set，以及逻辑控制指令if、break和return以供用户完成一些简单的需求而不必注册handler 该阶段的请求未被匹配至具体的location中 SERVER_REWRITE阶段的checker函数同样调用handler函数，但处理方式稍有不同，当handler返回NGX_DECLINED时进入下一阶段 NGX_HTTP_FIND_CONFIG_PHASE 这一阶段根据重写过的uri查找对应的location，可能被执行多次 通过ngx_http_core_find_location函数完成对r-&gt;loc_conf的设置，然后调用ngx_http_update_location_config更新请求相关配置 NGX_HTTP_REWRITE_PHASE location级别的重写阶段，该阶段执行location基本的重写指令，可能被执行多次。 与SERVER_REWRITE的逻辑基本相同，使用相同的handler函数，只是执行的时机不同。 NGX_HTTP_POST_REWRITE_PHASE 该阶段不能挂载handler，仅用于检查REWRITE阶段是否进行uri重写，若发生重写则返回再次执行REWRITE阶段，默认限制的重写次数为10次 介入该阶段的模块同样是rewrite模块 NGX_HTTP_PREACCESS_PHASE 访问权限控制的前一阶段，进入这一阶段时请求的loc_conf配置已经确定，在此阶段一般用于进行资源配置，限制连接数或请求速率。 ngx_http_limit_conn_module和ngx_http_limit_req_module等模块会在该阶段注册handler NGX_HTTP_ACCESS_PHASE 访问权限控制阶段,例如基于ip黑白名单的权限控制，或者基于用户名密码的权限控制。 默认情况下nginx 的 ngx_http_access_module和ngx_http_auth_basic_module模块分别会在该阶段注册一个handler 需要注意的是在此阶段需要满足所有的handler验证，即所有handler返回NGX_OK时，该阶段的checker函数才会进入下一阶段。 NGX_HTTP_POST_ACCESS_PHASE 此阶段仅根据ACCESS阶段的执行结果进行相应处理，不能挂载handler。 当ACCESS阶段返回NGX_HTTP_FORBIDDEN或NGX_HTTP_UNAUTHORIZED时，会在此阶段结束请求 NGX_HTTP_TRY_FILES_PHASE 处理try_files指令，如果没有配置try_files指令，该阶段会被跳过。 try_file指令用于检查指定的一个或多个文件或目录是否存在，若存在则执行之后的阶段，否则返回指定的lcoation或指定的返回码 此阶段不能挂载handler NGX_HTTP_CONTENT_PHASE 内容生成阶段，该阶段产生响应，并发送至客户端 在CONTENT阶段中，checker函数首先检查是否设置了content_handler，这里的content_handler不同于挂载在执行链上的handler，是每个location都可以独立拥有的，若存在则nginx在CONTENT阶段会直接执行content_handler，而不会再执行本阶段的handler。 在执行content_handler之前，nginx会将请求的write_event设置为ngx_http_request_empty_handler，这表示如果模块所设置的content_handler涉及到IO操作，则需要合理的设置读写 事件handler 同样的nginx将r-&gt;content_handler(r)的返回值直接传入ngx_http_finalize_request中，因此如果content_handler并未完成整个请求的处理，就需要设置合适的返回值并将请求的引用 计数加1以防请求被释放 如果没有注册content_handler，则与之前的阶段类似，checker会调用handler函数，而由于CONTENT是ngx_http_core_run_phases的最后一个阶段，因此若handler未返回NGX_DECLINED，checker将会结束请求并返回NGX_OK，否则将会返回NGX_FORBIDDEN或NGX_HTTP_NOT_FOUND NGX_HTTP_LOG_PHASE 日志记录阶段，该阶段记录访问日志，进入该阶段标明该请求的响应已经发送到系统的发送缓冲区中。 LOG阶段的执行位于ngx_http_free_request中，在这个阶段中会遍历LOG阶段的所有handler并执行 HTTP proxy模块HttpProxy模块用于将请求导向其他服务 Nginx与客户端使用HTTP&#x2F;1.1通信，而在后台服务使用HTTP&#x2F;1.0通信 在Nginx中, HTTP proxy模块介入于HTTP处理流程的CONTENT阶段，proxy模块通过”proxy_pass”配置的ngx_http_proxy_handler（位于ngx_http_proxy_module.c)中 rc = ngx_http_read_client_request_body(r, ngx_http_upstream_init); 设置处理请求的post_hadnler为ngx_http_upstream_init 而在 ngx_http_read_client_request_body 中 12345if (r != r-&gt;main || r-&gt;request_body || r-&gt;discard_body) &#123; r-&gt;request_body_no_buffering = 0; post_handler(r); return NGX_OK; &#125; 将请求交由upstream处理 部分proxy模块配置 proxy_pass：用于指定方向代理服务器的服务器池proxy_set_header:用于添加一些请求头，传递至代理服务器。 例如 proxy_set_header Host $http_host 用于区分后端主机 proxy_set_header X-Real_IP $remote_addr 以便后端获得客户端的真实IPproxy_body_buffer_size:指定缓冲区大小proxy_connect_timeout:指定与后端连接的超时时间proxy_send_timeout:指定后端服务器的数据回传超时时间 upstream模块Upstream模块与Handler相似，区别在于upstream模块不产生内容,而是通过请求后端服务器得到内容，在使用中upstream模块只需开发若干回调函数，完成构造请求和解析响应等工作 upstream模块的处理流程 1.创建upstream数据结构2.设置模块的tag和schema,其中schema用于日志，tag用于buf_chain管理3.设置upstream的后端服务器列表4.设置upstream回调函数5.创建并设置upstream环境6.完成初始化并进行收尾工作 此upstream的实际行为主要有两点，同上游主机建立连接并获取资源，以及将从上游主机中获取到的资源转发至下游客户端 而在同上游主机建立连接之前，nginx首先需要决定应当同 upstream 配置的后端主机列表中的哪一个建立连接 负载均衡模块用于从 upstream 指令所定义的后端主机列表中选取一台主机，以便进行之后建立连接以及获取相应的资源。 nginx内置的负载均衡模块主要有两种，默认为轮询模式，另一种则是ip_hash模式 ip_hash的主要逻辑位于 ngx_http_upstream_ip_hash 中，在这里这个函数主要做了两件事，对uscf-&gt;flags进行设置，以及设置init_upstream的回调函数为 ngx_http_upstream_init_ip_hash 在 ngx_http_upstream_init_ip_hash 中upstream将peer.init 设置为 ngx_http_upstream_init_ip_hash_peer（这个函数将会在 upstream 初始化请求时被调用） 通过调用peer.init，nginx会为每一个请求构造一张包含所有可用的upstream服务器的表，用于负载均衡计算以及提供当服务器宕机时的储备 同样在 ip_hash_peer 中，将upstream-&gt;peer.get的回调函数设置为 ngx_http_upstream_get_ip_hash_peer该函数负责从服务器表中取出某个服务器，通过get函数的返回值，nginx可以了解是否存在可用连接以及连接是否被建立 可能的返回值如下： 123NGX_DONE: 得到连接地址，且连接已被建立NGX_OK: 得到连接地址，但连接并未建立NGX_BUSY: 所有连接均不可用 得到并建立一个连接之后,upstream就可以尝试向此连接中发送请求头和请求体了，upstream使用 ngx_http_upstream_send_request 向后端发送请求 而在得到来自上游服务器的响应之后，upstream通过 ngx_http_upstream_process_header 将来自上游服务器的响应内容进行处理，并通过 ngx_http_upstream_send_response 返回至客户端 最后，upstream通过 peer.free 和 ngx_http_upstream_finalize 释放资源和连接 以上就是 Nginx 多阶段处理 Http 请求的全部过程","tags":["Nginx"]},{"path":"/google2ffb9a159ec4029a.html","content":"google-site-verification: google2ffb9a159ec4029a.html"}]